{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'../input/titanic/train.csv' does not exist: b'../input/titanic/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9d178f9a64df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#Грузим датасеты и смотрим на данные\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input/titanic/train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mtrain_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Pclass'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sex'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Age'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SibSp'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Parch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Fare'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Embarked'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Survived'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../input/titanic/train.csv' does not exist: b'../input/titanic/train.csv'"
     ]
    }
   ],
   "source": [
    "#Импорт библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Библиотеки визуализаций\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#Методы ML\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Грузим датасеты и смотрим на данные\n",
    "dataset = pd.read_csv('train.csv')\n",
    "train_x = dataset[['Pclass', 'Sex', 'Age', 'SibSp','Parch', 'Fare', 'Embarked']]\n",
    "train_y = dataset['Survived'].values \n",
    "\n",
    "testdata= pd.read_csv('test.csv')\n",
    "test_x= testdata[train_x.columns.values] #makes it same size as train_x column wise\n",
    "\n",
    "print(dataset.shape, train_x.shape, train_y.shape, test_x.shape)\n",
    "train_x.head(10) #train_x.head()\n",
    "\n",
    "test_x.head(5)\n",
    "\n",
    "#Проверяем наличие отсутствующих значений\n",
    "print('train описание данных:')\n",
    "dataset.info(),\n",
    "print('\\n','test описание данных:')\n",
    "test_x.info()\n",
    "\n",
    "#Смотрим ключевые метрики на датасете\n",
    "dataset.describe()\n",
    "\n",
    "#Строим график выживаемости по возрастам. Видим что только 38% выжило, при этом большинство - подростки\n",
    "figure, axis = plt.subplots(1,1,figsize=(20,3))\n",
    "age = dataset[[\"Age\", \"Survived\"]].groupby(['Age'],as_index=False).mean()\n",
    "sns.barplot(x='Age', y='Survived', data= age)\n",
    "\n",
    "figure = plt.figure(figsize=(13,8))\n",
    "plt.hist([train_x[dataset['Survived']==1]['Age'].dropna(),train_x[dataset['Survived']==0]['Age'].dropna()], stacked=True, color = ['r','b'], bins = 30,label = ['Survived','Dead'])\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Passengers Count')\n",
    "plt.legend()\n",
    "\n",
    "#заполняем пустые значения в возрастах медианным возрастом\n",
    "age_fill = [train_x['Age'].median(), test_x['Age'].median()]\n",
    "train_x['Age'].fillna(age_fill[0], inplace=True)\n",
    "test_x['Age'].fillna(age_fill[1], inplace=True)\n",
    "\n",
    "#Загоняем оба датасета в единый датафрейм для удобства манипуляций с данными\n",
    "print (train_x.shape, train_y.shape)\n",
    "combined = train_x.append(test_x) #[featureset, test_x]\n",
    "print (type(combined), combined.shape)\n",
    "\n",
    "survived_peeps = train_x[dataset['Survived']==1]['Sex'].value_counts()\n",
    "dead_peeps = train_x[dataset['Survived']==0]['Sex'].value_counts()\n",
    "df = pd.DataFrame([survived_peeps,dead_peeps])\n",
    "df.index = ['Survived','Dead']\n",
    "print (df)\n",
    "df.plot(kind='bar',stacked=True, figsize=(12,6))\n",
    "\n",
    "#На построенном выше графике видим корреляцию между выживаемостью и полом-женщины составляют большинство выживших\n",
    "#Заменяем качественную переменную пола количественной\n",
    "fixSex = combined['Sex'].copy().values\n",
    "fixSex[fixSex == 'male'] = 0  \n",
    "fixSex[fixSex == 'female'] = 1 \n",
    "fixSex.shape\n",
    "\n",
    "grid = sns.FacetGrid(dataset, col ='Sex', size = 3.2, aspect =1.7)\n",
    "grid.map(sns.barplot, 'Embarked','Survived', alpha= 0.6, ci = None)\n",
    "\n",
    "combined['Embarked'].fillna(combined['Embarked'].mode()[0], inplace=True) #filling Null vals in Embarked column\n",
    "fixEmb = combined['Embarked'].copy().values\n",
    "\n",
    "#Выживших женщин существенно больше вне зависимости от порта посадки\n",
    "\n",
    "fixEmb[fixEmb =='S'] = 0 #Меняем опять качественную переменную на количественную\n",
    "fixEmb[fixEmb =='C'] = 1\n",
    "fixEmb[fixEmb =='Q'] = 2\n",
    "fixEmb.shape\n",
    "\n",
    "#Проверка на пустоты и заполнение\n",
    "combined['Fare'].fillna(combined['Fare'].median(), inplace=True)\n",
    "combined.info() #везде нет отсутствующих значений\n",
    "\n",
    "#Начинаем процедуру замены не числовых значений на числовые\n",
    "print (combined.shape)\n",
    "combined.head(15) #датасет до трансформации в числовой\n",
    "\n",
    "\n",
    "allnum_dataset = combined.copy()\n",
    "allnum_dataset.loc[:,'Sex'] = fixSex \n",
    "allnum_dataset.loc[:,'Embarked'] = fixEmb\n",
    "allnum_dataset.head(15) #датасет после трансформации в числовой\n",
    "\n",
    "#Разделяем тренировочный и тестовые датасеты из датафрейма\n",
    "X = allnum_dataset.copy()[:891]\n",
    "test_x=  allnum_dataset.copy()[891:]\n",
    "X.shape, test_x.shape #разделенный датафрейм на два датасета\n",
    "\n",
    "\n",
    "#Тренировочные и проверочные данные разделяем для точной оценки модели SVM\n",
    "XtrainV, XtestV, ytrainV, ytestV = train_test_split(X,train_y, test_size = 0.30)\n",
    "XtrainV.shape, ytrainV.shape, XtestV.shape, ytestV.shape  # X = XtrainV(70%) + XtestV(30%), train_y = ytrainV(70%) +ytestV(30%)\n",
    "\n",
    "\n",
    "cla_sv =svm.SVC()# SVM- rbf kernel классификатор\n",
    "cla_sv\n",
    "\n",
    "\n",
    "print (\"размер проверочных тренировочных данных:\",\"X inputs->\", XtrainV.shape,\", y targets-> \", ytrainV.shape)\n",
    "cla_sv.fit(XtrainV, ytrainV)\n",
    "print (\"\\n\",\"ожидаемая точность:\",cla_sv.score(XtrainV, ytrainV))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print (\"размер проверочных тестовых данных:\",\"X inputs->\", XtestV.shape,\", y targets-> \", ytestV.shape)\n",
    "ypred = cla_sv.predict(XtestV)\n",
    "print (\"\\n\",\"ожидаемая точность прогноза:\", metrics.accuracy_score(ytestV, ypred))\n",
    "\n",
    "\n",
    "#Применяем RBF kernel SVM на полных тренировочных данных\n",
    "print (\"размер всего тренингового набора данных:\",\"X inputs->\", X.shape,\", y targets-> \", train_y.shape)\n",
    "cla_sv.fit(X, train_y)\n",
    "print (\"\\n\",\"ожидаемая точность прогноза:\", cla_sv.score(X, train_y))\n",
    "\n",
    "\n",
    "print (\"размер всего тестового набора данных:\",\"X inputs->\", test_x.shape,  \"y targets->\", test_x.shape[0])\n",
    "target_sv = cla_sv.predict(test_x)\n",
    "submission_sv= pd.DataFrame({'PassengerId':testdata['PassengerId'].values, 'Survived': target_sv})\n",
    "\n",
    "\n",
    "submission_sv.shape\n",
    "submission_sv.head(10)\n",
    "submission_sv.to_csv('submission_sv.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
